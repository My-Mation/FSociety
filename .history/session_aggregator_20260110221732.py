"""
Session Aggregator Module
Fetches and aggregates raw_audio + esp32_data for a given time window.
Produces a token-efficient JSON payload for Gemini (without calling it).

This module is ADDITIVE - it does NOT modify any existing tables or logic.
"""

import os
import json
import requests
from datetime import datetime

# Gemini API key from environment
GEMINI_API_KEY = os.getenv('GEMINI_API_KEY', 'AIzaSyAwopfQLPFjFWUPQWmPTMMVB-IkNVEK2_s')

# FIXED: Use ONLY valid Gemini models with FULL names (confirmed by ListModels)
# Order: cheapest/fastest first for fallback
GEMINI_MODELS = [
    "models/gemini-2.0-flash-lite",  # Fastest, most likely to succeed
    "models/gemini-2.0-flash",       # Fast, reliable
    "models/gemini-2.5-flash-lite",  # Newer, lite version
    "models/gemini-2.5-flash",       # Newest flash model
]


# System prompt for Gemini
GEMINI_SYSTEM_PROMPT = """You are an industrial machine diagnostics assistant.

You will be given a SINGLE machine session summary as structured JSON.
This data was generated by deterministic signal-processing code and
represents aggregated sensor behavior over a fixed time window.

IMPORTANT RULES:
- Do NOT assume missing data.
- Do NOT invent sensors or values.
- Base all conclusions strictly on the provided JSON.
- If evidence is weak, say so explicitly.

TASK:
Analyze the session summary and return your response in STRICT JSON
using EXACTLY the following schema:

{
  "health_status": "NORMAL | WARNING | CRITICAL",
  "key_findings": [
    {
      "signal": "sound | vibration | gas | combined",
      "observation": "short factual observation",
      "interpretation": "likely technical meaning",
      "confidence": "LOW | MEDIUM | HIGH"
    }
  ],
  "overall_severity": "LOW | MEDIUM | HIGH",
  "recommended_actions": [
    "action item 1",
    "action item 2"
  ],
  "notes": "optional clarifications or uncertainty"
}

SESSION SUMMARY:
"""


def call_gemini_with_fallback(session_data: dict) -> dict:
    """
    Send session data to Gemini API with model fallback.
    
    Valid models (from ListModels API):
    - models/gemini-2.0-flash-lite (fastest, cheapest)
    - models/gemini-2.0-flash
    - models/gemini-2.5-flash-lite
    - models/gemini-2.5-flash
    
    Args:
        session_data: The aggregated session payload
    
    Returns:
        dict: { "model_used": str, "analysis": dict }
    
    Raises:
        ValueError: If API key not configured
        RuntimeError: If all models fail
    """
    if not GEMINI_API_KEY:
        raise ValueError("GEMINI_API_KEY not configured")
    
    # Build compact prompt (token-efficient)
    prompt = GEMINI_SYSTEM_PROMPT + json.dumps(session_data, separators=(",", ":"))
    
    headers = {"Content-Type": "application/json"}
    
    # ✅ FIXED: Remove responseMimeType - not supported in REST API
    payload = {
        "contents": [{"parts": [{"text": prompt}]}],
        "generationConfig": {
            "temperature": 0.2,
            "maxOutputTokens": 512
        }
    }
    
    last_error = None
    
    for model in GEMINI_MODELS:
        # Model already includes "models/" prefix, use v1beta endpoint
        url = (
            f"https://generativelanguage.googleapis.com/v1beta/"
            f"{model}:generateContent?key={GEMINI_API_KEY}"
        )
        
        try:
            print(f"[GEMINI] Trying model: {model}")
            response = requests.post(url, json=payload, headers=headers, timeout=30)
            
            if response.status_code == 200:
                result = response.json()
                text = result["candidates"][0]["content"]["parts"][0]["text"]
                print(f"[GEMINI] ✅ Success with model: {model}")
                
                # ✅ FIXED: Defensive JSON parsing
                try:
                    analysis = json.loads(text)
                except json.JSONDecodeError:
                    # Model returned non-JSON, wrap it
                    print(f"[GEMINI] ⚠️ Non-JSON response, wrapping...")
                    analysis = {
                        "health_status": "WARNING",
                        "key_findings": [{
                            "signal": "combined",
                            "observation": "AI returned unstructured response",
                            "interpretation": text[:300] if len(text) > 300 else text,
                            "confidence": "LOW"
                        }],
                        "overall_severity": "MEDIUM",
                        "recommended_actions": ["Review raw AI output below"],
                        "notes": text[:500] if len(text) > 500 else text
                    }
                
                return {
                    "model_used": model,
                    "analysis": analysis
                }
            
            # Explicit quota / permission failures - try next model
            if response.status_code in (403, 429):
                error_detail = ""
                try:
                    error_detail = response.json().get('error', {}).get('message', '')
                except:
                    pass
                last_error = f"{model}: quota/permission denied ({response.status_code}) {error_detail}"
                print(f"[GEMINI] ⚠️ {last_error}")
                continue
            
            # Other errors
            error_detail = ""
            try:
                error_detail = response.json().get('error', {}).get('message', response.text[:200])
            except:
                error_detail = response.text[:200]
            last_error = f"{model}: HTTP {response.status_code} - {error_detail}"
            print(f"[GEMINI] ⚠️ {last_error}")
            
        except requests.exceptions.Timeout:
            last_error = f"{model}: request timeout"
            print(f"[GEMINI] ⚠️ {last_error}")
        except Exception as e:
            last_error = f"{model}: exception {str(e)}"
            print(f"[GEMINI] ⚠️ {last_error}")
    
    # If ALL models fail
    raise RuntimeError(
        f"All Gemini models unavailable. Last error: {last_error}"
    )


def call_gemini_api(session_data: dict) -> dict:
    """
    DEPRECATED: Use call_gemini_with_fallback() instead.
    Kept for backward compatibility.
    """
    result = call_gemini_with_fallback(session_data)
    return result["analysis"]
    raise Exception(f"Failed to parse Gemini response: {str(e)}")


def get_latest_data_range(conn, duration_seconds: int = 60) -> dict:
    """
    Get the latest data time range from the database.
    Returns start/stop timestamps based on the most recent audio data.
    
    Args:
        conn: PostgreSQL connection object
        duration_seconds: How many seconds of data to include (default 60)
    
    Returns:
        dict with 'start', 'stop', 'has_data', 'audio_count', 'esp32_count'
    """
    cursor = conn.cursor()
    try:
        # Get latest audio timestamp
        cursor.execute("""
            SELECT 
                MAX(timestamp) - INTERVAL '%s seconds' AS start_ts,
                MAX(timestamp) AS stop_ts,
                COUNT(*) AS total_rows
            FROM raw_audio
        """ % duration_seconds)
        row = cursor.fetchone()
        
        if not row or not row[1]:
            return {
                "has_data": False,
                "start": None,
                "stop": None,
                "audio_count": 0,
                "esp32_count": 0,
                "message": "No audio data in database"
            }
        
        start_ts = row[0]
        stop_ts = row[1]
        
        # Count audio rows in this range
        cursor.execute("""
            SELECT COUNT(*) FROM raw_audio 
            WHERE timestamp BETWEEN %s AND %s
        """, (start_ts, stop_ts))
        audio_count = cursor.fetchone()[0]
        
        # Count ESP32 rows in this range
        cursor.execute("""
            SELECT COUNT(*) FROM esp32_data 
            WHERE timestamp BETWEEN %s AND %s
        """, (start_ts, stop_ts))
        esp32_count = cursor.fetchone()[0]
        
        return {
            "has_data": audio_count > 0,
            "start": start_ts.isoformat() if start_ts else None,
            "stop": stop_ts.isoformat() if stop_ts else None,
            "audio_count": audio_count,
            "esp32_count": esp32_count,
            "message": f"Found {audio_count} audio rows, {esp32_count} ESP32 rows"
        }
        
    finally:
        cursor.close()


def validate_time_range(conn, start_ts: str, stop_ts: str) -> dict:
    """
    Validate that the requested time range has data.
    Returns validation result with counts.
    """
    cursor = conn.cursor()
    try:
        # Count audio rows
        cursor.execute("""
            SELECT COUNT(*) FROM raw_audio 
            WHERE timestamp BETWEEN %s AND %s
        """, (start_ts, stop_ts))
        audio_count = cursor.fetchone()[0]
        
        # Count ESP32 rows
        cursor.execute("""
            SELECT COUNT(*) FROM esp32_data 
            WHERE timestamp BETWEEN %s AND %s
        """, (start_ts, stop_ts))
        esp32_count = cursor.fetchone()[0]
        
        # Get actual data boundaries
        cursor.execute("SELECT MIN(timestamp), MAX(timestamp) FROM raw_audio")
        audio_range = cursor.fetchone()
        
        return {
            "valid": audio_count > 0 or esp32_count > 0,
            "audio_count": audio_count,
            "esp32_count": esp32_count,
            "audio_earliest": str(audio_range[0]) if audio_range[0] else None,
            "audio_latest": str(audio_range[1]) if audio_range[1] else None,
            "requested_start": start_ts,
            "requested_stop": stop_ts
        }
        
    finally:
        cursor.close()


def aggregate_session_data(conn, start_ts: str, stop_ts: str, machine_id: str = None, device_id: str = None):
    """
    Fetch and aggregate data from raw_audio and esp32_data between start and stop timestamps.
    
    Args:
        conn: PostgreSQL connection object
        start_ts: ISO timestamp string (e.g., "2026-01-10T10:00:00")
        stop_ts: ISO timestamp string (e.g., "2026-01-10T10:30:00")
        machine_id: Optional filter for raw_audio
        device_id: Optional filter for esp32_data
    
    Returns:
        dict: Aggregated session payload (ready for Gemini)
    
    Raises:
        ValueError: If no data exists in the selected time range
    """
    cursor = conn.cursor()
    
    try:
        # =====================
        # 0. VALIDATE TIME RANGE (Hard Guard)
        # =====================
        cursor.execute("""
            SELECT COUNT(*) FROM raw_audio
            WHERE timestamp BETWEEN %s AND %s
        """, (start_ts, stop_ts))
        audio_count = cursor.fetchone()[0]
        
        cursor.execute("""
            SELECT COUNT(*) FROM esp32_data
            WHERE timestamp BETWEEN %s AND %s
        """, (start_ts, stop_ts))
        esp32_count = cursor.fetchone()[0]
        
        if audio_count == 0 and esp32_count == 0:
            # Get actual data range to help user
            cursor.execute("SELECT MIN(timestamp), MAX(timestamp) FROM raw_audio")
            actual_range = cursor.fetchone()
            raise ValueError(
                f"No data exists in selected time range ({start_ts} to {stop_ts}). "
                f"Actual data range: {actual_range[0]} to {actual_range[1]}"
            )
        
        # Parse timestamps for duration calculation
        start_dt = datetime.fromisoformat(start_ts.replace('Z', '+00:00').replace('+00:00', ''))
        stop_dt = datetime.fromisoformat(stop_ts.replace('Z', '+00:00').replace('+00:00', ''))
        duration_sec = (stop_dt - start_dt).total_seconds()
        
        # =====================
        # 1. AGGREGATE RAW_AUDIO (Sound Data)
        # =====================
        sound_summary = aggregate_sound_data(cursor, start_ts, stop_ts, machine_id, conn)
        
        # =====================
        # 2. AGGREGATE ESP32_DATA (Vibration + Gas)
        # =====================
        vibration_summary, gas_summary, resolved_device_id = aggregate_esp32_data(
            cursor, start_ts, stop_ts, device_id
        )
        
        # =====================
        # 3. BUILD FINAL PAYLOAD
        # =====================
        payload = {
            "machine_id": machine_id or sound_summary.get("detected_machine_id", "unknown"),
            "device_id": resolved_device_id or device_id or "unknown",
            "session": {
                "start": start_ts,
                "stop": stop_ts,
                "duration_sec": round(duration_sec, 1)
            },
            "sound_summary": {
                "data_mode": sound_summary.get("data_mode", "unknown"),
                "dominant_freq_median": sound_summary.get("dominant_freq_median", 0),
                "freq_iqr": sound_summary.get("freq_iqr", [0, 0]),
                "out_of_profile_events": sound_summary.get("out_of_profile_events", 0)
            },
            "vibration_summary": vibration_summary,
            "gas_summary": gas_summary
        }
        
        return payload
        
    finally:
        cursor.close()


def aggregate_sound_data(cursor, start_ts: str, stop_ts: str, machine_id: str, conn):
    """
    Aggregate sound data from raw_audio table.
    Computes median frequency, IQR, and out-of-profile event count.
    
    Uses controlled fallback:
    1. Try LIVE data first (preferred for real-time diagnostics)
    2. Fallback to CALIBRATION data if no live data exists
    3. Data modes are NEVER mixed
    """
    def fetch(mode):
        q = """
            SELECT dominant_freq, freq_confidence, machine_id
            FROM raw_audio
            WHERE timestamp BETWEEN %s AND %s
              AND dominant_freq IS NOT NULL
              AND dominant_freq > 0
              AND mode = %s
        """
        params = [start_ts, stop_ts, mode]
        if machine_id:
            q += " AND machine_id = %s"
            params.append(machine_id)
        q += " ORDER BY timestamp"
        cursor.execute(q, params)
        return cursor.fetchall()

    # 1. Try LIVE first
    rows = fetch("live")
    data_mode = "live"

    # 2. Fallback to CALIBRATION if no live data
    if not rows:
        rows = fetch("calibration")
        data_mode = "calibration"

    # 3. No data at all
    if not rows:
        return {
            "data_mode": "none",
            "dominant_freq_median": 0,
            "freq_iqr": [0, 0],
            "out_of_profile_events": 0,
            "detected_machine_id": machine_id
        }

    # Extract frequencies
    frequencies = [r[0] for r in rows if r[0] and r[0] > 0]
    
    # Detect machine_id if not provided
    detected_machine_id = machine_id or max(
        (r[2] for r in rows if r[2]), default=None
    )

    if not frequencies:
        return {
            "data_mode": data_mode,
            "dominant_freq_median": 0,
            "freq_iqr": [0, 0],
            "out_of_profile_events": 0,
            "detected_machine_id": detected_machine_id
        }

    # Sort for percentile calculations
    frequencies.sort()
    n = len(frequencies)

    # Compute median
    median = (
        frequencies[n // 2]
        if n % 2
        else (frequencies[n // 2 - 1] + frequencies[n // 2]) / 2
    )

    # Compute IQR (25th and 75th percentiles)
    q1 = frequencies[int(0.25 * (n - 1))]
    q3 = frequencies[int(0.75 * (n - 1))]

    # Only compare against profiles in LIVE mode (calibration IS the profile)
    out_of_profile = (
        count_out_of_profile_events(conn, frequencies, detected_machine_id)
        if data_mode == "live" and detected_machine_id
        else 0
    )

    return {
        "data_mode": data_mode,
        "dominant_freq_median": round(median, 2),
        "freq_iqr": [round(q1, 2), round(q3, 2)],
        "out_of_profile_events": out_of_profile,
        "detected_machine_id": detected_machine_id
    }


def count_out_of_profile_events(conn, frequencies: list, machine_id: str) -> int:
    """
    Count how many frequency readings fall outside the machine's calibrated IQR range.
    """
    cursor = conn.cursor()
    try:
        cursor.execute(
            "SELECT iqr_low, iqr_high FROM machine_profiles WHERE machine_id = %s",
            (machine_id,)
        )
        row = cursor.fetchone()
        
        if not row:
            return 0
        
        iqr_low, iqr_high = row
        out_of_range = sum(1 for f in frequencies if f < iqr_low or f > iqr_high)
        return out_of_range
        
    finally:
        cursor.close()


def aggregate_esp32_data(cursor, start_ts: str, stop_ts: str, device_id: str = None):
    """
    Aggregate ESP32 sensor data (vibration + gas).
    Returns vibration_summary, gas_summary, and resolved device_id.
    """
    # Build query with optional device_id filter
    query = """
        SELECT vibration, event_count, gas_raw, gas_status, device_id
        FROM esp32_data
        WHERE timestamp >= %s AND timestamp <= %s
    """
    params = [start_ts, stop_ts]
    
    if device_id:
        query += " AND device_id = %s"
        params.append(device_id)
    
    query += " ORDER BY timestamp"
    
    cursor.execute(query, params)
    rows = cursor.fetchall()
    
    if not rows:
        return (
            {"avg": 0, "peak": 0, "event_count": 0},
            {"avg_raw": 0, "peak_raw": 0, "status": "LOW"},
            device_id
        )
    
    # Extract values
    vibrations = []
    event_counts = []
    gas_raws = []
    gas_statuses = []
    resolved_device_id = device_id
    
    for row in rows:
        vib, evt, gas, status, dev_id = row
        
        if vib is not None:
            # Reverse vibration logic: 0 = active, 1 = inactive
            # Convert to activity percentage (0 -> 100%, 1 -> 0%)
            activity = (1 - vib) * 100 if vib <= 1 else 0
            vibrations.append(activity)
        
        if evt is not None:
            event_counts.append(evt)
        
        if gas is not None and gas > 0:
            gas_raws.append(gas)
        
        if status:
            gas_statuses.append(status)
        
        if not resolved_device_id and dev_id:
            resolved_device_id = dev_id
    
    # Vibration summary
    vib_avg = sum(vibrations) / len(vibrations) if vibrations else 0
    vib_peak = max(vibrations) if vibrations else 0
    total_events = sum(event_counts) if event_counts else 0
    
    vibration_summary = {
        "avg": round(vib_avg, 1),
        "peak": round(vib_peak, 1),
        "event_count": total_events
    }
    
    # Gas summary
    gas_avg = sum(gas_raws) / len(gas_raws) if gas_raws else 0
    gas_peak = max(gas_raws) if gas_raws else 0
    
    # Determine overall gas status
    gas_status = determine_gas_status(gas_avg, gas_statuses)
    
    gas_summary = {
        "avg_raw": round(gas_avg, 1),
        "peak_raw": round(gas_peak, 1),
        "status": gas_status
    }
    
    return vibration_summary, gas_summary, resolved_device_id


def determine_gas_status(avg_gas: float, statuses: list) -> str:
    """
    Determine overall gas status based on average value and collected statuses.
    """
    # Priority: if any DANGER/RISK, mark HIGH
    if any(s in ['DANGER', 'RISK', 'HAZARDOUS'] for s in statuses):
        return "HIGH"
    
    # By average value thresholds
    if avg_gas > 2000:
        return "HIGH"
    elif avg_gas > 800:
        return "MEDIUM"
    else:
        return "LOW"


def get_gemini_api_key_status() -> dict:
    """
    Check if Gemini API key is configured (without exposing it).
    """
    key = os.getenv('GEMINI_API_KEY', '')
    return {
        "configured": bool(key and len(key) > 10),
        "key_preview": f"{key[:4]}...{key[-4:]}" if key and len(key) > 10 else "NOT_SET"
    }
